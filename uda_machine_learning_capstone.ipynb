{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified. .\\train.zip\n",
      "Found and verified. .\\test.zip\n"
     ]
    }
   ],
   "source": [
    "#================1.retrieve data===========================\n",
    "import sys\n",
    "import os\n",
    "import urllib.request\n",
    "import getpass\n",
    "import requests\n",
    "\n",
    "def verify_datasize(filename, expected_bytes):\n",
    "    statinfo = os.stat(filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print(\"Found and verified.\", filename)\n",
    "    else:\n",
    "        raise Exception(\"Failed to veryfile file [{}], file_size [{}], expected_size [{}].\".format(filename, statinfo.st_size, expected_bytes))\n",
    "\n",
    "        \n",
    "#Reports every 5% change in download progress\n",
    "last_percent_reported = None\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "    global last_percent_reported\n",
    "    percent = int(count * blockSize * 100) / totalSize\n",
    "    if last_percent_reported != percent:\n",
    "        if percent % 5 == 0:\n",
    "            sys.stdout.write(\"%s%%\" % percent)\n",
    "        else:\n",
    "            sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "    last_percent_reported = percent\n",
    "\n",
    "    \n",
    "#download a file from url and check size\n",
    "data_root = \".\" #data saved local directory\n",
    "\n",
    "urls = [['https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/download/train.zip', 569918665],\n",
    "      ['https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/download/test.zip',284478493]]\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'\n",
    "}\n",
    "\n",
    "def download_data_without_Authentication(url, expected_bytes, force=False):\n",
    "    dest_filename = os.path.join(data_root,url.split('/')[-1])\n",
    "    if force or not os.path.exists(dest_filename):\n",
    "        print(\"Attempting to download data from :\", url)\n",
    "        urllib.request.urlretrieve(url, dest_filename, download_progress_hook)\n",
    "        print(\"\\nDownload completed!\")\n",
    "    verify_datasize(dest_filename, expected_bytes)\n",
    "    return dest_filename\n",
    "\n",
    "#first you must login to Kaggle, direct to the specific competition, and accept rules competition, or post will direct to rules page.\n",
    "#eg:dogs-vs-cats's rule page is:https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/rules\n",
    "def download_data_with_Authentication(url, expected_bytes, force=False):\n",
    "    dest_filename = os.path.join(data_root, url.split('/')[-1])\n",
    "    if force or not os.path.exists(dest_filename):\n",
    "        print(\"Attempting to download data from :\", url)\n",
    "        user_name = input(\"Enter username:\")\n",
    "        pwd = getpass.getpass(\"Enter password:\")\n",
    "        authen_info = {'UserName':user_name, 'Password': pwd}\n",
    "        \n",
    "        #To go to the redirect url\n",
    "        resp = requests.get(url, headers=headers)\n",
    "        print(\"Redirected:\", resp.url)\n",
    "\n",
    "        #To login and get data\n",
    "        resp = requests.post(resp.url, data = authen_info, headers=headers,stream=True)\n",
    "        print(\"Redirected:\", resp.url)\n",
    "        print(\"Status:\", resp.status_code)\n",
    "        \n",
    "        if resp.status_code == requests.codes.ok:\n",
    "            f = open(dest_filename, 'wb')\n",
    "            for chunk in resp.iter_content(chunk_size = 512 * 1024):# Reads 512KB at a time into memory\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "            f.close()\n",
    "            print(\"\\nDownload completed!\")\n",
    "        else:\n",
    "            raise Exception(\"\\nDownload failed\")\n",
    "        \n",
    "    verify_datasize(dest_filename, expected_bytes)\n",
    "    return dest_filename\n",
    "   \n",
    "\n",
    "train_filename = download_data_with_Authentication(urls[0][0], urls[0][1])\n",
    "test_filename = download_data_with_Authentication(urls[1][0], urls[1][1])        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzip file {} succeed. .\\train.zip\n",
      "Unzip file {} succeed. .\\test.zip\n"
     ]
    }
   ],
   "source": [
    "#=================2.unzip file and preprocess image files======================\n",
    "import zipfile\n",
    "\n",
    "def unzip_file(filename):\n",
    "    file_to_unzip = zipfile.ZipFile(filename)\n",
    "    file_to_unzip.extractall()\n",
    "    file_to_unzip.close()\n",
    "    print(\"Unzip file succeed.\", filename)\n",
    "    \n",
    "unzip_file(train_filename)\n",
    "unzip_file(test_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "dat_dir = \"./trainprocess\"\n",
    "cate_dat_dir = dat_dir + \"/categorized\"\n",
    "cate_dog_dir = cate_dat_dir + \"/dog\"\n",
    "cate_cat_dir = cate_dat_dir + \"/cat\"\n",
    "train_dat_dir = dat_dir + \"/train\"\n",
    "train_dog_dir = train_dat_dir + \"/dog\"\n",
    "train_cat_dir = train_dat_dir + \"/cat\"\n",
    "valid_dat_dir = dat_dir + \"/valid\"\n",
    "valid_dog_dir = valid_dat_dir + \"/dog\"\n",
    "valid_cat_dir = valid_dat_dir + \"/cat\"\n",
    "dirs = [dat_dir, cate_dat_dir, cate_dog_dir, cate_cat_dir,\n",
    "       train_dat_dir, train_dog_dir, train_cat_dir,\n",
    "       valid_dat_dir, valid_dog_dir, valid_cat_dir]\n",
    "\n",
    "def prepare_dir(path):\n",
    "    for dir in dirs:\n",
    "        if os.path.exists(dir):\n",
    "            shutil.rmtree(dir)\n",
    "        os.mkdir(dir)\n",
    "        \n",
    "def rearrange_data():\n",
    "    train_filenames = os.listdir('./train')\n",
    "    train_dog = filter(lambda x:x[:3] == 'dog', train_filenames)\n",
    "    train_cat = filter(lambda x:x[:3] == 'cat', train_filenames)\n",
    "    for filename in train_dog:\n",
    "        shutil.copy(\"./train/\" + filename, cate_dog_dir)\n",
    "    for filename in train_cat:\n",
    "        shutil.copy(\"./train/\" + filename, cate_cat_dir)\n",
    "        \n",
    "def split_train_valid(test_size, random_seed):\n",
    "    \n",
    "        \n",
    "#prepare_dir(dirs)    \n",
    "#rearrange_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
