{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified. ./train.zip\n",
      "Found and verified. ./test.zip\n"
     ]
    }
   ],
   "source": [
    "#================1.retrieve data===========================\n",
    "import sys\n",
    "import os\n",
    "import urllib.request\n",
    "import getpass\n",
    "import requests\n",
    "\n",
    "def verify_datasize(filename, expected_bytes):\n",
    "    statinfo = os.stat(filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print(\"Found and verified.\", filename)\n",
    "    else:\n",
    "        raise Exception(\"Failed to veryfile file [{}], file_size [{}], expected_size [{}].\".format(filename, statinfo.st_size, expected_bytes))\n",
    "\n",
    "        \n",
    "#Reports every 5% change in download progress\n",
    "last_percent_reported = None\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "    global last_percent_reported\n",
    "    percent = int(count * blockSize * 100) / totalSize\n",
    "    if last_percent_reported != percent:\n",
    "        if percent % 5 == 0:\n",
    "            sys.stdout.write(\"%s%%\" % percent)\n",
    "        else:\n",
    "            sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "    last_percent_reported = percent\n",
    "\n",
    "    \n",
    "#download a file from url and check size\n",
    "data_root = \".\" #data saved local directory\n",
    "\n",
    "urls = [['https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/download/train.zip', 569918665],\n",
    "      ['https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/download/test.zip',284478493]]\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'\n",
    "}\n",
    "\n",
    "def download_data_without_Authentication(url, expected_bytes, force=False):\n",
    "    dest_filename = os.path.join(data_root,url.split('/')[-1])\n",
    "    if force or not os.path.exists(dest_filename):\n",
    "        print(\"Attempting to download data from :\", url)\n",
    "        urllib.request.urlretrieve(url, dest_filename, download_progress_hook)\n",
    "        print(\"\\nDownload completed!\")\n",
    "    verify_datasize(dest_filename, expected_bytes)\n",
    "    return dest_filename\n",
    "\n",
    "#first you must login to Kaggle, direct to the specific competition, and accept rules competition, or post will direct to rules page.\n",
    "#eg:dogs-vs-cats's rule page is:https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/rules\n",
    "def download_data_with_Authentication(url, expected_bytes, force=False):\n",
    "    dest_filename = os.path.join(data_root, url.split('/')[-1])\n",
    "    if force or not os.path.exists(dest_filename):\n",
    "        print(\"Attempting to download data from :\", url)\n",
    "        user_name = input(\"Enter username:\")\n",
    "        pwd = getpass.getpass(\"Enter password:\")\n",
    "        authen_info = {'UserName':user_name, 'Password': pwd}\n",
    "        \n",
    "        #To go to the redirect url\n",
    "        resp = requests.get(url, headers=headers)\n",
    "        print(\"Redirected:\", resp.url)\n",
    "\n",
    "        #To login and get data\n",
    "        resp = requests.post(resp.url, data = authen_info, headers=headers,stream=True)\n",
    "        print(\"Redirected:\", resp.url)\n",
    "        print(\"Status:\", resp.status_code)\n",
    "        \n",
    "        if resp.status_code == requests.codes.ok:\n",
    "            f = open(dest_filename, 'wb')\n",
    "            for chunk in resp.iter_content(chunk_size = 512 * 1024):# Reads 512KB at a time into memory\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "            f.close()\n",
    "            print(\"\\nDownload completed!\")\n",
    "        else:\n",
    "            raise Exception(\"\\nDownload failed\")\n",
    "        \n",
    "    verify_datasize(dest_filename, expected_bytes)\n",
    "    return dest_filename\n",
    "   \n",
    "\n",
    "train_filename = download_data_with_Authentication(urls[0][0], urls[0][1])\n",
    "test_filename = download_data_with_Authentication(urls[1][0], urls[1][1])        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzip file succeed. ./train.zip\n",
      "Unzip file succeed. ./test.zip\n"
     ]
    }
   ],
   "source": [
    "#=================2.unzip file and explore image files======================\n",
    "import zipfile\n",
    "\n",
    "def unzip_file(filename):\n",
    "    file_to_unzip = zipfile.ZipFile(filename)\n",
    "    file_to_unzip.extractall()\n",
    "    file_to_unzip.close()\n",
    "    print(\"Unzip file succeed.\", filename)\n",
    "    \n",
    "unzip_file(train_filename)\n",
    "unzip_file(test_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrebuild_dir(dat_dir)\\nrebuild_dir(cate_dat_dir)\\ndog_counts = rearrange_data(\"dog\")\\ncat_counts = rearrange_data(\"cat\")\\nimage_properties_dog = get_image_properties(\"dog\")\\nimage_properties_cat = get_image_properties(\"cat\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "dat_dir = \"./trainprocess\"\n",
    "cate_dat_dir = dat_dir + \"/categorized\"\n",
    "train_dat_dir = dat_dir + \"/train\"\n",
    "valid_dat_dir = dat_dir + \"/valid\"\n",
    "categories = [\"cat\", \"dog\"]\n",
    "\n",
    "def rebuild_dir(dir):\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.mkdir(dir)\n",
    "        \n",
    "def rearrange_data(category_name):\n",
    "    if category_name not in categories:\n",
    "        raise Exception(\"\\n category [{}] not exists.\", category_name)\n",
    "        \n",
    "    category_data_dir = cate_dat_dir + \"/\" + category_name\n",
    "    rebuild_dir(category_data_dir)\n",
    "    \n",
    "    train_filenames = os.listdir('./train')\n",
    "    train_category = filter(lambda x:x[:3].upper() ==category_name.upper() , train_filenames)\n",
    "    train_count = 0\n",
    "    for filename in train_category:\n",
    "        train_count += 1\n",
    "        shutil.copy(\"./train/\" + filename, category_data_dir)\n",
    "    return train_count\n",
    " \n",
    "def get_image_properties(category_name):\n",
    "    if category_name not in categories:\n",
    "        raise Exception(\"\\n category {{}] not exists.\", category_name)\n",
    "        \n",
    "    category_map = {}\n",
    "    path = cate_dat_dir + \"/\" + category_name + \"/\"\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in filenames:\n",
    "        im = Image.open(path + filename)\n",
    "        category_map[filename] = [im.format, im.mode, im.width, im.height]\n",
    "    return category_map\n",
    "'''\n",
    "rebuild_dir(dat_dir)\n",
    "rebuild_dir(cate_dat_dir)\n",
    "dog_counts = rearrange_data(\"dog\")\n",
    "cat_counts = rearrange_data(\"cat\")\n",
    "image_properties_dog = get_image_properties(\"dog\")\n",
    "image_properties_cat = get_image_properties(\"cat\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_properties_dog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f80b81e0e5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf_dog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_properties_dog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_properties_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdf_dog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_properties_dog' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "columns = ['format', 'mode', 'width', 'height']\n",
    "\n",
    "df_dog = pd.DataFrame(image_properties_dog).transpose()\n",
    "df_cat = pd.DataFrame(image_properties_cat).transpose()\n",
    "df_dog.columns = columns\n",
    "df_cat.columns = columns\n",
    "\n",
    "print(\"\\ndogs count : [{}]. cats count:[{}]\".format(dog_counts, cat_counts))\n",
    "\n",
    "print(\"\\ndogs group by format, mode:\")\n",
    "print(df_dog.groupby(['format', 'mode'])['width'].count())\n",
    "print(\"\\ncats group by format, mode:\")\n",
    "print(df_cat.groupby(['format', 'mode'])['width'].count())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(x=df_dog['width'], y=df_dog['height'], s=10, marker=\".\", color='red')\n",
    "plt.scatter(x=df_cat['width'], y=df_cat['height'], s=10, marker=\"*\", color='blue')\n",
    "plt.legend(['dogs','cats'], loc='center right')\n",
    "plt.xlabel('widht')\n",
    "plt.ylabel('height')\n",
    "plt.title(\"image size\")\n",
    "plt.subplots_adjust(hspace = .5)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.boxplot([df_dog['width'], df_dog['height'], df_cat['width'], df_cat['height']], showmeans=True)\n",
    "plt.xticks([1,2,3,4], ['dog-width', 'dog-height', 'cat-width', 'cat-height'])\n",
    "#plt.subplots_adjust(hspace = .5)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\ndogs width max/min:\\n\",df_dog.loc[[df_dog['width'].idxmax(),df_dog['width'].idxmin()]])\n",
    "print(\"\\ndogs height max/min:\\n\",df_dog.loc[[df_dog['height'].idxmax(),df_dog['height'].idxmin()]])\n",
    "print(\"\\ncats width max/mai:\\n\",df_cat.loc[[df_cat['width'].idxmax(),df_cat['width'].idxmin()]])\n",
    "print(\"\\ncats height max/min:\\n\",df_cat.loc[[df_cat['height'].idxmax(),df_cat['height'].idxmin()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#========================3.split and preprocess data================================\n",
    "import random\n",
    "\n",
    "def split_train_valid(category_name, test_percent, random_seed=None, create_link=False):\n",
    "    if category_name not in categories:\n",
    "        raise Exception(\"\\n category [{}] note exists.\", category_name)\n",
    "    if test_percent <=0 or test_percent >=1:\n",
    "        raise Exception(\"\\n test_percent must be in (0,1)\")\n",
    "        \n",
    "    source_dir = cate_dat_dir + \"/\" + category_name + \"/\"\n",
    "    dest_train_dir = train_dat_dir + \"/\" + category_name + \"/\"\n",
    "    dest_valid_dir = valid_dat_dir + \"/\" + category_name + \"/\"\n",
    "    \n",
    "    filenames = os.listdir(source_dir)\n",
    "    total_size = len(filenames)\n",
    "    test_size = int(total_size * test_percent)\n",
    "    train_size = total_size - test_size\n",
    "    \n",
    "    if not random_seed is None:\n",
    "        random.seed(random_seed)\n",
    "    random.shuffle(filenames)\n",
    "    rebuild_dir(dest_train_dir)\n",
    "    rebuild_dir(dest_valid_dir)\n",
    "    for i in range(0, total_size):\n",
    "        if i < test_size:\n",
    "            dest_dir = dest_valid_dir\n",
    "        else:\n",
    "            dest_dir = dest_train_dir\n",
    "        \n",
    "        if create_link == True:\n",
    "                os.symlink(source_dir + filenames[i], dest_dir + filenames[i])\n",
    "        else:\n",
    "                shutil.copy(source_dir + filenames[i], dest_dir)\n",
    "                \n",
    "    return train_size, test_size\n",
    "\n",
    "rebuild_dir(train_dat_dir)\n",
    "rebuild_dir(valid_dat_dir)\n",
    "dog_train_size, dog_test_size = split_train_valid(\"dog\", 0.3, 1234, False)\n",
    "cat_train_size, cat_test_size = split_train_valid(\"cat\", 0.3, 1234, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17500 images belonging to 2 classes.\n",
      "Found 7500 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "17500/17500 [==============================] - 170s - loss: 0.6935 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.6930 - acc: 0.5138 - val_loss: 0.6831 - val_acc: 0.5533\n",
      "Epoch 3/50\n",
      "17500/17500 [==============================] - 158s - loss: 0.6862 - acc: 0.5656 - val_loss: 0.6825 - val_acc: 0.5696\n",
      "Epoch 4/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.6807 - acc: 0.5622 - val_loss: 0.7509 - val_acc: 0.5569\n",
      "Epoch 5/50\n",
      "17500/17500 [==============================] - 159s - loss: 0.6623 - acc: 0.6087 - val_loss: 0.6600 - val_acc: 0.5805\n",
      "Epoch 6/50\n",
      "17500/17500 [==============================] - 158s - loss: 0.6222 - acc: 0.6610 - val_loss: 0.6332 - val_acc: 0.6543\n",
      "Epoch 7/50\n",
      "17500/17500 [==============================] - 158s - loss: 0.5924 - acc: 0.6881 - val_loss: 0.5898 - val_acc: 0.6757\n",
      "Epoch 8/50\n",
      "17500/17500 [==============================] - 158s - loss: 0.5535 - acc: 0.7179 - val_loss: 0.5137 - val_acc: 0.7456\n",
      "Epoch 9/50\n",
      "17500/17500 [==============================] - 158s - loss: 0.5269 - acc: 0.7382 - val_loss: 0.6767 - val_acc: 0.6141\n",
      "Epoch 10/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.4974 - acc: 0.7579 - val_loss: 0.4519 - val_acc: 0.7859\n",
      "Epoch 11/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.4696 - acc: 0.7717 - val_loss: 0.4904 - val_acc: 0.7789\n",
      "Epoch 12/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.4455 - acc: 0.7902 - val_loss: 0.4355 - val_acc: 0.8009\n",
      "Epoch 13/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.4262 - acc: 0.8039 - val_loss: 0.4437 - val_acc: 0.7836\n",
      "Epoch 14/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.3964 - acc: 0.8176 - val_loss: 0.3703 - val_acc: 0.8363\n",
      "Epoch 15/50\n",
      "17500/17500 [==============================] - 156s - loss: 0.3867 - acc: 0.8225 - val_loss: 0.3550 - val_acc: 0.8431\n",
      "Epoch 16/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.3477 - acc: 0.8465 - val_loss: 0.3780 - val_acc: 0.8300\n",
      "Epoch 17/50\n",
      "17500/17500 [==============================] - 159s - loss: 0.3268 - acc: 0.8555 - val_loss: 0.3379 - val_acc: 0.8569\n",
      "Epoch 18/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.3088 - acc: 0.8645 - val_loss: 0.3503 - val_acc: 0.8471\n",
      "Epoch 19/50\n",
      "17500/17500 [==============================] - 158s - loss: 0.2869 - acc: 0.8801 - val_loss: 0.4570 - val_acc: 0.7776\n",
      "Epoch 20/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.2707 - acc: 0.8851 - val_loss: 0.2933 - val_acc: 0.8719\n",
      "Epoch 21/50\n",
      "17500/17500 [==============================] - 160s - loss: 0.2511 - acc: 0.8919 - val_loss: 0.2626 - val_acc: 0.8919\n",
      "Epoch 22/50\n",
      "17500/17500 [==============================] - 158s - loss: 0.2276 - acc: 0.9034 - val_loss: 0.2442 - val_acc: 0.8997\n",
      "Epoch 23/50\n",
      "17500/17500 [==============================] - 158s - loss: 0.2240 - acc: 0.9034 - val_loss: 0.2227 - val_acc: 0.9044\n",
      "Epoch 24/50\n",
      "17500/17500 [==============================] - 158s - loss: 0.2061 - acc: 0.9142 - val_loss: 0.2238 - val_acc: 0.9107\n",
      "Epoch 25/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.1974 - acc: 0.9170 - val_loss: 0.2188 - val_acc: 0.9069\n",
      "Epoch 26/50\n",
      "17500/17500 [==============================] - 157s - loss: 0.1820 - acc: 0.9238 - val_loss: 0.4271 - val_acc: 0.8156\n",
      "Epoch 27/50\n",
      "17500/17500 [==============================] - 156s - loss: 0.1803 - acc: 0.9254 - val_loss: 0.1903 - val_acc: 0.9223\n",
      "Epoch 28/50\n",
      "17500/17500 [==============================] - 158s - loss: 0.1780 - acc: 0.9249 - val_loss: 0.1802 - val_acc: 0.9244\n",
      "Epoch 29/50\n",
      "12800/17500 [====================>.........] - ETA: 28s - loss: 0.1654 - acc: 0.9301"
     ]
    }
   ],
   "source": [
    "# model_case1 \n",
    "import ModelUtil\n",
    "\n",
    "dat_dir = \"./trainprocess\"\n",
    "cate_dat_dir = dat_dir + \"/categorized\"\n",
    "train_dat_dir = dat_dir + \"/train\"\n",
    "valid_dat_dir = dat_dir + \"/valid\"\n",
    "categories = [\"cat\", \"dog\"]\n",
    "\n",
    "total_train_size = 17500 #dog_train_size + cat_train_size\n",
    "total_valid_size = 7500 #dog_test_size + cat_test_size\n",
    "image_width=150\n",
    "image_height=150\n",
    "perbatch = 128\n",
    "poch_num = 50\n",
    "\n",
    "name_case1 = \"model_case1\"\n",
    "model1= ModelUtil.model_case1(image_width, image_height)\n",
    "model1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "ModelUtil.visualize_model(model1, model_name=name_case1)\n",
    "history_case1 = ModelUtil.train_data(model1, model_name=name_case1, epoch=poch_num,\n",
    "                          image_size = (image_width, image_height), num_perbatch=perbatch,\n",
    "                          train_dir=train_dat_dir, train_size=total_train_size,\n",
    "                          valid_dir=valid_dat_dir, valid_size=total_valid_size)\n",
    "ModelUtil.visualize_history(history_case1, model_name=name_case1)\n",
    "ModelUtil.predict_data(model1, model_name=name_case1, \n",
    "                 image_size=(image_width, image_height), \n",
    "                 num_perbatch=perbatch)\n",
    "ModelUtil.save_model(model1, model_name=name_case1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_vgg19\n",
    "import ModelUtil\n",
    "\n",
    "total_train_size = 17500 #dog_train_size + cat_train_size\n",
    "total_valid_size = 7500 #dog_test_size + cat_test_size\n",
    "image_width=400\n",
    "image_height=400\n",
    "image_size = (image_width,image_height)\n",
    "perbatch = 64\n",
    "poch_num = 10\n",
    "\n",
    "name_vgg19 = \"model_vgg19\"\n",
    "model_vgg19 = ModelUtil.model_vgg19(image_width, image_height)\n",
    "model_vgg19.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ModelUtil.visualize_model(model_vgg19, model_name=name_vgg19)\n",
    "history_vgg19 = ModelUtil.train_data(model_vgg19, model_name=name_vgg19, epoch=poch_num,\n",
    "                          image_size = (image_width, image_height), num_perbatch=perbatch,\n",
    "                          train_dat_dir, total_train_size,\n",
    "                          valid_dat_dir, total_valid_size)\n",
    "ModelUtil.visualize_history(history_vgg19, model_name=name_vgg19)\n",
    "ModelUtil.predict_data(model_vgg19, model_name=name_vgg19, \n",
    "                 image_size=(image_width, image_height), \n",
    "                 num_perbatch=perbatch)\n",
    "ModelUtil.save_model(model_vgg19, model_name=name_vgg190)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
